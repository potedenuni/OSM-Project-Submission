{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenStreetMap Data Case Study\n",
    "## Map Area: Dallas, United States\n",
    "\n",
    "https://mapzen.com/data/metro-extracts/metro/dallas_texas/\n",
    "\n",
    "Having lived in the Dallas area for over 15 years, I am very interested in working with this region."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems Researched and Encountered In The Map\n",
    "\n",
    "Extracting a subset of the Dallas OSM file using the code provided in the Project Instructions, initially I used a k value of 100 (1% sample) to create CSV files for each of the following:\n",
    "\n",
    "    Nodes\n",
    "    Node Tags\n",
    "    Ways\n",
    "    Ways Tags\n",
    "    Ways Nodes\n",
    "\n",
    "Eventually, to increases the size of the data source, I repeated much of the analysis with a k value of 35 which allowed for a 50MB+ OSM file.  Of most interest was the Node Tags and Ways Tags as these provide a majority of the user provided data that is most subject to error.\n",
    "\n",
    "The following potential data problems were researched:\n",
    "1. Erroneous city names.\n",
    "2. Zip Code accuracy.\n",
    "3. Abbreviations in Street Names.\n",
    "\n",
    "This output can be replicated by executing the code within \"Create CSV.ipynb,\" then starting an SQLite3 session and performing the command \".read import_csv.sql\" which will remove any previous instances of the dallas.db and reinitialize the database with the current content of the .csv files.  Some of the illustritive information below came from the initial pull (k=100), however, output of a full session performing the embedded SQL statements against the larger data set below will be included in \"OSM_SQL.txt\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Erroneous city names\n",
    "\n",
    "Using a query shared in the sample by github user carlward, I summarized the values in the city tags.\n",
    "\n",
    "    SELECT tags.value, COUNT(*) as count \n",
    "    FROM (SELECT * FROM nodes_tags UNION ALL \n",
    "          SELECT * FROM ways_tags) tags\n",
    "    WHERE tags.key LIKE '%city'\n",
    "    GROUP BY tags.value\n",
    "    ORDER BY count DESC;\n",
    "    \n",
    "Surprisingly, this list represented a very high degree of accuracy, however there were two obvious errors involving city names with only numbers.  (This query summary was pulled with sample k value of 100.  Subsequently, a larger sample was pulled with a k value of 35.  A review of that data confirmed the level of accuracy and identified one city with a city name of \"15.\"  Other items that could be resolved involved capitalization.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|City|Count|\n",
    "|:---|---|\n",
    "|Frisco|495|\n",
    "|Plano|27|\n",
    "|Fort Worth|8|\n",
    "|Dallas|7|\n",
    "|Cedar Hill|4|\n",
    "|McKinney|4|\n",
    "|Waxahachie|4|\n",
    "|Irving|3|\n",
    "|Wylie|3|\n",
    "|Grand Prairie|2|\n",
    "|The Colony|2|\n",
    "|100|1|\n",
    "|2|1|\n",
    "|Arlington|1|\n",
    "|Corinth|1|\n",
    "|Denton|1|\n",
    "|Duncanville|1|\n",
    "|Euless|1|\n",
    "|Farmers Branch|1|\n",
    "|Keller|1|\n",
    "|Kennedale|1|\n",
    "|Lewisville|1|\n",
    "|Little Elm|1|\n",
    "|Mansfield|1|\n",
    "|Mesquite|1|\n",
    "|Nevada|1|\n",
    "|Palmer|1|\n",
    "|Richardson|1|\n",
    "|Rockwall|1|\n",
    "|Saginaw|1|\n",
    "|Southlake|1|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the following query I was able to isolate only these rows which contain numeric values.\n",
    "\n",
    "    SELECT tags.value, COUNT(*) as count\n",
    "    FROM (SELECT * FROM nodes_tags UNION ALL \n",
    "          SELECT * FROM ways_tags) tags\n",
    "    WHERE tags.key LIKE '%city'\n",
    "    AND tags.value GLOB '*[0-9]*'\n",
    "    GROUP BY tags.value\n",
    "    ORDER BY count DESC;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For purposes of this project, the decision was made to clean this data by providing a reliable alph-only value in the City field, and thus instances city fields containing non-alpha characters were simply deleted.  However, given more time and the proper source data, a more thourough cleaning method would involve the comparison of other fields (most notably the zip code) to a reference source and correcting the city using this information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    UPDATE nodes_tags\n",
    "    SET value = ''\n",
    "    WHERE key LIKE '%city'\n",
    "    AND value GLOB '*[0-9]*';\n",
    "\n",
    "    UPDATE ways_tags\n",
    "    SET value = ''\n",
    "    WHERE key LIKE '%city'\n",
    "    AND value GLOB '*[0-9]*';\n",
    "    \n",
    "To verify updates, the following select was performed and confirmed that no matching data existed in the database.\n",
    "    \n",
    "    SELECT tags.value, COUNT(*) as count\n",
    "    FROM (SELECT * FROM nodes_tags UNION ALL \n",
    "          SELECT * FROM ways_tags) tags\n",
    "    WHERE tags.key LIKE '%city'\n",
    "    AND tags.value GLOB '*[0-9]*'\n",
    "    GROUP BY tags.value\n",
    "    ORDER BY count DESC;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "NOTE: One unique situation may affect the accuracy of this \"more thorough\" cleaning.  In at least one instance in the Dallas area (zip code 76179), there are two possible city mappings (Fort Worth and Saginaw) that could be correct.  Further analysis by street address or GPS coordinates may be required to truly correct the instance of the incorrect city."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Zip Code Accuracy\n",
    "\n",
    "Using the following query (slightly modified from the above query taken from the sample) I was able to find all zip codes represented within the sampled list.\n",
    "\n",
    "    SELECT tags.value, COUNT(*) as count\n",
    "    FROM (SELECT * FROM nodes_tags UNION ALL \n",
    "          SELECT * FROM ways_tags) tags\n",
    "    WHERE tags.key = 'postcode'\n",
    "    GROUP BY tags.value\n",
    "    ORDER BY tags.value;\n",
    "    \n",
    "This search actually returned no questionable values.  All zip codes returned were either 750xx, 751xx, 752xx, 760xx, 761xx or 762xx.  Using the following resource (as well as personal knowledge of the area) all of these zip code prefixes are in the area generally referred to as the Dallas (or Dallas-Fort Worth) area.\n",
    "\n",
    "https://en.wikipedia.org/wiki/List_of_ZIP_code_prefixes#Starts_with_7\n",
    "\n",
    "However, while the City search on the sampled data returned over 1500 city tags, the zip code search returned fewer than 100 matching tags.  This suggests that while the values may be largely accurate, many of the records appear to be missing this data altogether.\n",
    "\n",
    "This search would be repeated on gradually larger samples of the data set, each time comparing the summarized results to expected values and looking for obvious outliers.  Examples of outliers here could be:\n",
    "* Zip codes with fewer than 5 digits.\n",
    "* Zip codes with more than 5 digits but fewer than 9 digits (including and excluding a possible - character).\n",
    "* Zip codes with more than 9 digits (excluding any possible - characters).\n",
    "* Zip codes with values other than digits.\n",
    "\n",
    "An example of the update queries to remove erroneous zip codes containing non-digits would be:\n",
    "\n",
    "    UPDATE nodes_tags\n",
    "    SET value = ''\n",
    "    WHERE key='%postcode'\n",
    "    AND value GLOB '*[^0-9]*';\n",
    "    \n",
    "    UPDATE ways_tags\n",
    "    SET value = ''\n",
    "    WHERE key='postcode'\n",
    "    AND value GLOB '*[^0-9]*';\n",
    "    \n",
    "Because this data set only contained one entry with non-digits, \"TX 76262\", the correction was obvious and rather than deleting it, the decision was made to directly modify it to its proper value of \"76262\" using the following query:\n",
    "\n",
    "    UPDATE nodes_tags\n",
    "    SET value = '76262'\n",
    "    WHERE key='postcode'\n",
    "    AND value = 'TX 76262';\n",
    "    \n",
    "To verify the update was successful, the followng query is used before and after the above update query:\n",
    "    \n",
    "    SELECT *\n",
    "    FROM nodes_tags\n",
    "    WHERE key='postcode'\n",
    "    AND value GLOB '*[^0-9]*';\n",
    "\n",
    "\n",
    "An example of the update queries to remove erroneous zip codes with length less than 5 digits would be:\n",
    "    \n",
    "    UPDATE nodes_tags\n",
    "    SET value = ''\n",
    "    WHERE key='postcode'\n",
    "    AND LENGTH(value) < 5;\n",
    "    \n",
    "    UPDATE ways_tags\n",
    "    SET value = ''\n",
    "    WHERE key='postcode'\n",
    "    AND LENGTH(value) < 5;\n",
    "\n",
    "An example of the update queries to remove erroneous zip codes with only digits and length longer than 9 characters:\n",
    "\n",
    "    UPDATE nodes_tags\n",
    "    SET value = ''\n",
    "    WHERE key='postcode'\n",
    "    AND value GLOB '*[0-9]*'\n",
    "    AND LENGTH(value) > 9;\n",
    "    \n",
    "    UPDATE ways_tags\n",
    "    SET value = ''\n",
    "    WHERE key='postcode'\n",
    "    AND value GLOB '*[0-9]*'\n",
    "    AND LENGTH(value) > 9;\n",
    "    \n",
    "An example of the update queries to remove erroneous zip codes with only digits and the - character and length longer than 10 characters:\n",
    "\n",
    "    UPDATE nodes_tags\n",
    "    SET value = ''\n",
    "    WHERE key='postcode'\n",
    "    AND value GLOB '*[0-9]-[0-9]*'\n",
    "    AND LENGTH(value) > 10;\n",
    "    \n",
    "    UPDATE ways_tags\n",
    "    SET value = ''\n",
    "    WHERE key='postcode'\n",
    "    AND value GLOB '*[0-9]-[0-9]*'\n",
    "    AND LENGTH(value) > 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Abbreviations In Street Names\n",
    "\n",
    "Seeing the evidence of inconsistencies in street naming and abbreviations, this seemed a good place to look within this data set.  However, once again, the Dallas OSM data is REMARKABLY clean!  Using the following query I identified 7,922 unique street names in the database:\n",
    "\n",
    "    SELECT tags.value, COUNT(*) as count\n",
    "    FROM (SELECT * FROM nodes_tags UNION ALL \n",
    "          SELECT * FROM ways_tags) tags\n",
    "    WHERE tags.key = 'street'\n",
    "    GROUP BY tags.value\n",
    "    ORDER BY count DESC;\n",
    "    \n",
    "Looking through the results, the first item identified was that in some cases \"Avenue B\" was entered as \"Ave B,\" for example.  A quick glance through the remaining data showed that abbreviations for directions (North, etc.) were all but non-existent.  In addition, words like \"Drive,\" \"Street,\" etc., were all but perfectly uniform with no abbreviations.  It seems that this data set was either input from an already uniformly formatted source or has already been \"wrangled.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview Of The Data\n",
    "\n",
    "### File Sizes\n",
    "\n",
    "    dallas_texas.osm ...... 55,136 KB\n",
    "    dallas.db ............. 31,802 KB\n",
    "    nodes.csv ............. 22,737 KB\n",
    "    nodes_tags.csv ........... 363 KB\n",
    "    ways.csv ............... 1,749 KB\n",
    "    ways_tags.csv .......... 6,725 KB\n",
    "    ways_nodes.cv .......... 3,635 KB\n",
    "\n",
    "### Number of Nodes\n",
    "    SELECT COUNT(*) FROM nodes;\n",
    "\n",
    "* 249,683\n",
    "\n",
    "### Number of Ways\n",
    "    SELECT COUNT(*) FROM ways;\n",
    "    \n",
    "* 25,934\n",
    "\n",
    "### Number of Unique Users\n",
    "    SELECT COUNT(DISTINCT(e.uid))          \n",
    "    FROM (SELECT uid FROM nodes UNION ALL SELECT uid FROM ways) e;\n",
    "\n",
    "* 1,103\n",
    "\n",
    "### Top 10 Contributing Users\n",
    "    SELECT e.user, COUNT(*) as num\n",
    "    FROM (SELECT user FROM nodes UNION ALL SELECT user FROM ways) e\n",
    "    GROUP BY e.user\n",
    "    ORDER BY num DESC\n",
    "    LIMIT 10;\n",
    "    \n",
    "    Andrew Matheny_import... 174,102\n",
    "    woodpeck_fixbot.......... 29,508\n",
    "    Andrew Matheny............ 7,634\n",
    "    Stephen214................ 6,339\n",
    "    TheDude05................. 4,124\n",
    "    TexasNHD.................. 2,514\n",
    "    25or6to4.................. 2,429\n",
    "    RoadGeek_MD99............. 1,808\n",
    "    Chris Lawrence............ 1,696\n",
    "    Dami_Tn................... 1,487\n",
    "\n",
    "### Number of users appearing only once (having 1 post)\n",
    "    SELECT COUNT(*) \n",
    "    FROM\n",
    "        (SELECT e.user, COUNT(*) as num\n",
    "         FROM (SELECT user FROM nodes UNION ALL SELECT user FROM ways) e\n",
    "         GROUP BY e.user\n",
    "         HAVING num=1)  u;\n",
    "\n",
    "* 338\n",
    "\n",
    "### Top 10 Described Amenities\n",
    "    SELECT tags.value, COUNT(*) as count\n",
    "    FROM (SELECT * FROM nodes_tags UNION ALL \n",
    "          SELECT * FROM ways_tags) tags\n",
    "    WHERE tags.key = 'amenity'\n",
    "    GROUP BY tags.value\n",
    "    ORDER BY count DESC\n",
    "    LIMIT 10;\n",
    "\n",
    "    parking............ 151\n",
    "    place_of_worship.... 92\n",
    "    school.............. 55\n",
    "    fast_food........... 47\n",
    "    restaurant.......... 47\n",
    "    fuel................ 31\n",
    "    bank................ 14\n",
    "    bench................ 8\n",
    "    grave_yard........... 7\n",
    "    hospital............. 7\n",
    "\n",
    "### Key Types\n",
    "    SELECT tags.key, COUNT(*) as count\n",
    "    FROM (SELECT * FROM nodes_tags UNION ALL \n",
    "          SELECT * FROM ways_tags) tags\n",
    "    GROUP BY tags.key\n",
    "    ORDER BY count DESC\n",
    "    LIMIT 10;\n",
    "    \n",
    "* 285 different tipes of keys represented.\n",
    "* Top 10 most common:\n",
    "\n",
    "        building...... 16,946\n",
    "        street........ 14,754\n",
    "        housenumber... 14,753\n",
    "        highway........ 8,442\n",
    "        county......... 5,015\n",
    "        cfcc........... 5,008\n",
    "        name........... 4,960\n",
    "        reviewed....... 4,409\n",
    "        name_base...... 3,428\n",
    "        source......... 3,292"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Ideas\n",
    "\n",
    "Other potential areas of investigation, given more time and resources might be:\n",
    "\n",
    "1. Given more time and the proper source data, a more thourough cleaning method would involve the comparison of other fields (most notably the zip code) to a reference source and correcting the city using this information.\n",
    "2. Similarly the missing zip code data could be largely remedied by comparison to a city/zip reference table or an available geographic zip code match.\n",
    "3. Based on the sample data, it is clear that, within the Dallas Fort Worth Metroplex, someone is keenly interested in the accuracy of the Frisco area.  Frisco is one of the most popular residential suburbs in the metroplex, so the robustness of this area's data is not surprising, however, for this OSM data to be remotely reflective of the \"Greater Dallas/Fort Worth Metroplex,\" much more data for the areas other than Frisco is needed.\n",
    "4. There are many entries in the data labeled \"FIXME\" indicating that there is a clear need for update to the record.  These records can be identified with the following query:\n",
    "\n",
    "        SELECT *\n",
    "        FROM (SELECT * FROM nodes_tags UNION ALL \n",
    "              SELECT * FROM ways_tags) tags\n",
    "        WHERE tags.key LIKE 'fixme';\n",
    "  \n",
    "  Further investigation here could be under taken.\n",
    "\n",
    "However, the problem with this data is much bigger than typographical errors contained within.  The problem is that the commercialization of this information is so advanced now that the real world value of the information collected is questionable when compared with robust tools like WAZE, Google Maps, Yahoo Maps, Apple Maps, etc.  Because these tools have monetized the data in such a way that is it hard to keep up with the quality that is invested in these tools.  The excercise is extremely valuable as used here, as a learning tool because it is so well structured, and while woefully incomplete, it is still robust enough to challenge the student of data science to break out of habits such as using Excel to perform analysis because of limited data sets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
